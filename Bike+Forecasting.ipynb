{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bike Rental Forecasting using LSTM based Network #\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Please install the following packages before proceeding. Open command line interface from Azure Machine Learning Workbench App and execute the following commands:\n",
    "\n",
    "- pip install tensorflow\n",
    "- pip install keras\n",
    "- pip install h5py\n",
    "- pip uninstall azure-ml-api-sdk\n",
    "- pip install azure-ml-api-sdk\n",
    "- pip uninstall azure-cli-ml\n",
    "- pip install azure-cli-ml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import newaxis\n",
    "import keras\n",
    "import datetime\n",
    "import random\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, LSTM, TimeDistributed\n",
    "from sklearn import metrics as mt\n",
    "\n",
    "import pandas as pd\n",
    "from keras import optimizers\n",
    "import datetime\n",
    "\n",
    "slidingwindow = 12\n",
    "maxval_w = 1\n",
    "maxval_pb = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_data(df, window_sz):\n",
    "    data = np.squeeze(np.reshape(df, newshape= [-1,1]), axis=1)\n",
    "    \n",
    "    init = np.zeros(window_sz)\n",
    "    result=[]\n",
    "    data = np.append(init,data)\n",
    "    #print(data[0:34])\n",
    "    \n",
    "    for index in range(window_sz,len(data)):\n",
    "        tmp=[]\n",
    "        tmp = data[index-window_sz:index]\n",
    "        #tmp = data[2:14]\n",
    "        rsed_arr = tmp[::-1]\n",
    "        #result.append(np.append([data[index]],tmp))\n",
    "        result.append(rsed_arr)\n",
    "    result=np.array(result)\n",
    "    print(result.shape)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(fname):\n",
    "    global noballs, slidingwindow, norm_wndw\n",
    "    print(\"*** loading data ***\")\n",
    "    df = pd.read_csv(fname)\n",
    "\n",
    "    data = np.array(df.iloc[:, 12])\n",
    "    \n",
    "    trainX = parse_data(data, slidingwindow)\n",
    "    df = np.concatenate((trainX,df), axis=1)\n",
    "\n",
    "    print(\"Data has size of \", data.shape)\n",
    "    print(\"Sample data on how lag features look for the forecast:\\n\",trainX[0:20:,])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** loading data ***\n",
      "(17379, 12)\n",
      "Data has size of  (17379,)\n",
      "Sample data on how lag features look for the forecast:\n",
      " [[   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.]\n",
      " [  16.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.]\n",
      " [  40.   16.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.]\n",
      " [  32.   40.   16.    0.    0.    0.    0.    0.    0.    0.    0.    0.]\n",
      " [  13.   32.   40.   16.    0.    0.    0.    0.    0.    0.    0.    0.]\n",
      " [   1.   13.   32.   40.   16.    0.    0.    0.    0.    0.    0.    0.]\n",
      " [   1.    1.   13.   32.   40.   16.    0.    0.    0.    0.    0.    0.]\n",
      " [   2.    1.    1.   13.   32.   40.   16.    0.    0.    0.    0.    0.]\n",
      " [   3.    2.    1.    1.   13.   32.   40.   16.    0.    0.    0.    0.]\n",
      " [   8.    3.    2.    1.    1.   13.   32.   40.   16.    0.    0.    0.]\n",
      " [  14.    8.    3.    2.    1.    1.   13.   32.   40.   16.    0.    0.]\n",
      " [  36.   14.    8.    3.    2.    1.    1.   13.   32.   40.   16.    0.]\n",
      " [  56.   36.   14.    8.    3.    2.    1.    1.   13.   32.   40.   16.]\n",
      " [  84.   56.   36.   14.    8.    3.    2.    1.    1.   13.   32.   40.]\n",
      " [  94.   84.   56.   36.   14.    8.    3.    2.    1.    1.   13.   32.]\n",
      " [ 106.   94.   84.   56.   36.   14.    8.    3.    2.    1.    1.   13.]\n",
      " [ 110.  106.   94.   84.   56.   36.   14.    8.    3.    2.    1.    1.]\n",
      " [  93.  110.  106.   94.   84.   56.   36.   14.    8.    3.    2.    1.]\n",
      " [  67.   93.  110.  106.   94.   84.   56.   36.   14.    8.    3.    2.]\n",
      " [  35.   67.   93.  110.  106.   94.   84.   56.   36.   14.    8.    3.]]\n"
     ]
    }
   ],
   "source": [
    "preppeddata=load_data(\"Regression_ Demand estimation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createDataset(df):\n",
    "    row = int(0.89971*df.shape[0])\n",
    "    traindf = df[0:row,:]\n",
    "    testdf = df[row:,:]\n",
    "    trainY=traindf[:,-1]\n",
    "    trainX=traindf[:,:-1]\n",
    "    testY = testdf[:,-1]\n",
    "    testX = testdf[:,:-1]\n",
    "    return trainX, trainY, testX, testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trX, trY, tsX, tsY = createDataset(preppeddata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train X shape (15636, 24)\n",
      "train Y shape (15636,)\n",
      "test X shape (1743, 24)\n",
      "test Y shape (1743,)\n"
     ]
    }
   ],
   "source": [
    "print(\"train X shape\", trX.shape)\n",
    "print(\"train Y shape\", trY.shape)\n",
    "print(\"test X shape\", tsX.shape)\n",
    "print(\"test Y shape\", tsY.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hyper_parameters(window_sz):\n",
    "    global units, dropouts, layers, outputunits, input_dim, batch_sz, numepochs\n",
    "    unitset  = [96, 96, 96, 96]\n",
    "    layerset = [1, 1, 1, 1, 1]\n",
    "    dropoutset = [0.4,0.4,0.4]\n",
    "    \n",
    "    layers = random.choice(layerset)\n",
    "    units = np.zeros(layers)\n",
    "    dropouts = np.zeros(layers)\n",
    "    batch_sz = 96\n",
    "    for i in range(0, layers):\n",
    "        units[i] = random.choice(unitset)\n",
    "        dropouts[i] = random.choice(dropoutset)\n",
    "    units[0] = batch_sz\n",
    "    \n",
    "    outputunits = 1\n",
    "    \n",
    "    numepochs = 10\n",
    "    \n",
    "    print(layers)\n",
    "    print(units)\n",
    "    print(dropouts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try creating network without dropouts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def setupNetwork(window_sz):\n",
    "    global units, dropouts, layers, outputunits\n",
    "    model = Sequential()\n",
    "\n",
    "    timestamps = 1\n",
    "    features = 24\n",
    "\n",
    "    model.add(keras.layers.LSTM(units=units[0].astype(\"int64\"), return_sequences=False, input_shape=(features, timestamps)))\n",
    "    #model.add(Dropout(dropouts[0]))\n",
    "    model.add(Dense(units=batch_sz*2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(timestamps))\n",
    "    model.add(Activation('linear'))\n",
    "\n",
    "    model.compile(loss='mse', optimizer='rmsprop')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[ 96.]\n",
      "[ 0.4]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 96)                37632     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 192)               18624     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 193       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 56,449\n",
      "Trainable params: 56,449\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "hyper_parameters(slidingwindow)\n",
    "model = setupNetwork(slidingwindow)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainModel(m, xtr, ytr, ep, bsz,l=0):\n",
    "    \n",
    "\n",
    "    m.fit(xtr, ytr, batch_size=bsz, epochs=ep, validation_split=0.079, verbose=l)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96\n",
      "Train on 14400 samples, validate on 1236 samples\n",
      "Epoch 1/1\n",
      "14s - loss: 33861.0920 - val_loss: 49550.7258\n"
     ]
    }
   ],
   "source": [
    "global batch_sz\n",
    "print(batch_sz)\n",
    "modelrest = trainModel(model, trX.reshape(-1,24,1), trY.reshape(-1,1), 1, batch_sz,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_perf(m, xts, yts):\n",
    "    ypred = m.predict(xts.reshape(xts.shape[0],24,-1))\n",
    "    py = np.squeeze(np.reshape(ypred, newshape= [-1,1]), axis=1)\n",
    "    r2 = mt.r2_score(yts, ypred)\n",
    "    #print(r2)\n",
    "    return r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run parameter sweep across batch and epoch to find the best parameters that give best R^2 value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parameter_sweep():\n",
    "    marr = np.empty((8,5), dtype=Sequential)\n",
    "    r2 = np.zeros((8,5))\n",
    "    rowcnt = 0\n",
    "    colcnt = 0\n",
    "    print(\"------------------------------------------------------\")\n",
    "    print(\"|     R^2    |            epochs                     |\")\n",
    "    print(\"------------------------------------------------------\")\n",
    "    print(\"| batch size | \",end=\"\")\n",
    "    for e in range(2,12,2):\n",
    "        print(\" %3d  | \"% e, end=\"\")\n",
    "    print()\n",
    "    print(\"------------------------------------------------------\")\n",
    "    for b in range(24,192,24):\n",
    "        colcnt = 0\n",
    "        print(\"|   %3d      |\"% b, end=\"\")\n",
    "        for e in range(2,12,2):\n",
    "            mtmp = setupNetwork(slidingwindow)\n",
    "            marr[rowcnt, colcnt] = trainModel(mtmp, trX.reshape(-1,24,1), trY.reshape(-1,1), e, b, 0)\n",
    "            r2[rowcnt, colcnt] = compute_perf(marr[rowcnt, colcnt], tsX, tsY)\n",
    "            \n",
    "            r = r2[rowcnt, colcnt]\n",
    "            print(\" %0.4f|\"% r,end=\"\")\n",
    "            colcnt += 1\n",
    "            #print(\"batch size = \", b, \" epochs = \", e, \" r^2 = \", r2[rowcnt, colcnt])\n",
    "        rowcnt +=1\n",
    "        print()\n",
    "    print(\"------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The comparable data using 12 lag features when trained on Azure ML v1 using Boosted decision tree gives R-Square value of 0.82. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running parameter sweep across various batch sizes and epochs taks almost 30 mins on 1 GPU based VM. So only run the cell below if you have 30 mins. Else use the data from my run as shown below which shows that batch size with 48 for 10 epochs gives the best result of R^2 being **0.8936** or use 24 batch size with 6 epochs for decent R^2 of **0.8711**. \n",
    "\n",
    "![](http://neerajkh.blob.core.windows.net/images/parametersweep_bikerental.PNG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start of parameter sweep: 2017-09-10 12:45:16.629069\n",
      "end of parameter sweep: 2017-09-10 12:45:16.630070\n",
      "total time =  0:00:00.001001\n"
     ]
    }
   ],
   "source": [
    "start = datetime.datetime.now()\n",
    "print(\"start of parameter sweep:\", start)\n",
    "#parameter_sweep()\n",
    "end = datetime.datetime.now()\n",
    "print(\"end of parameter sweep:\", end)\n",
    "print(\"total time = \", end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Running parameter sweep also provided hint that we can combine various batch sizes and epochs to get the best results. Here is the one way to do it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainWithVaryingBatchAndEpochs(m):\n",
    "    \n",
    "    b = 24\n",
    "    for e in range(2,8,2):      \n",
    "        m = trainModel(m, trX.reshape(-1,24,1), trY.reshape(-1,1), e, b, 0)\n",
    "        r2 = compute_perf(m, tsX, tsY)\n",
    "        print(\"At end of epoch %d \"% e, end=\"\")\n",
    "        print(\"using batch size of %d \"% b, end=\"\")\n",
    "        print(\"the r^2 is %0.4f|\"% r2)\n",
    "    b = 48\n",
    "    e = 2\n",
    "    m = trainModel(m, trX.reshape(-1,24,1), trY.reshape(-1,1), e, b, 0)\n",
    "    print(\"At end of epoch %d \"% e, end=\"\")\n",
    "    print(\"using batch size of %d \"% b, end=\"\")\n",
    "    print(\"the r^2 is %0.4f|\"% r2)\n",
    "    e = 4\n",
    "    m = trainModel(m, trX.reshape(-1,24,1), trY.reshape(-1,1), e, b, 0)\n",
    "    print(\"At end of epoch %d \"% e, end=\"\")\n",
    "    print(\"using batch size of %d \"% b, end=\"\")\n",
    "    print(\"the r^2 is %0.4f|\"% r2)\n",
    "    return m\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mtmp = setupNetwork(slidingwindow)\n",
    "#mtmp = trainWithVaryingBatchAndEpochs(mtmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can try to see if dropouts improve accuracy or not. So we will add dropouts with above configuration and try the new network with dropouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def setupNetworkWithDropouts(window_sz):\n",
    "    global units, dropouts, layers, outputunits\n",
    "    model = Sequential()\n",
    "\n",
    "    timestamps = 1\n",
    "    features = 24\n",
    "\n",
    "    model.add(keras.layers.LSTM(units=units[0].astype(\"int64\"), return_sequences=False, input_shape=(features, timestamps)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(units=batch_sz*2, activation='relu'))\n",
    "    \n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(timestamps, activation='linear'))\n",
    "    \n",
    "\n",
    "    model.compile(loss='mse', optimizer='rmsprop')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#anothermodel = setupNetworkWithDropouts(slidingwindow)\n",
    "#anothermodel = trainWithVaryingBatchAndEpochs(anothermodel) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have tried all alternatives, progressive batch/epoch, dropout etc., the simplest model that provides good accuracy is with batch size 48 and epoch 10. So for now, we will go with that model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, let's go with batch size of 48 and 10 epochs with no dropouts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14400 samples, validate on 1236 samples\n",
      "Epoch 1/10\n",
      "12s - loss: 11884.6534 - val_loss: 20991.9635\n",
      "Epoch 2/10\n",
      "12s - loss: 7221.2174 - val_loss: 16770.6625\n",
      "Epoch 3/10\n",
      "12s - loss: 5393.9261 - val_loss: 12856.9220\n",
      "Epoch 4/10\n",
      "12s - loss: 4482.3544 - val_loss: 11958.8152\n",
      "Epoch 5/10\n",
      "13s - loss: 3684.3524 - val_loss: 8890.5063\n",
      "Epoch 6/10\n",
      "13s - loss: 3303.2398 - val_loss: 12575.3209\n",
      "Epoch 7/10\n",
      "12s - loss: 3030.8193 - val_loss: 6506.9300\n",
      "Epoch 8/10\n",
      "12s - loss: 2800.8817 - val_loss: 14724.7015\n",
      "Epoch 9/10\n",
      "13s - loss: 2650.7879 - val_loss: 7395.3794\n",
      "Epoch 10/10\n",
      "12s - loss: 2568.6371 - val_loss: 6417.3821\n"
     ]
    }
   ],
   "source": [
    "finalmodel = setupNetwork(slidingwindow)\n",
    "finalmodel = trainModel(model, trX.reshape(-1,24,1), trY.reshape(-1,1), 10, 48,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 =  0.88287373615\n"
     ]
    }
   ],
   "source": [
    "print(\"R^2 = \", compute_perf(finalmodel, tsX, tsY))\n",
    "finalmodel.save(\"finalmodel.sav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operationalization ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for existing **scoring file** and if it exist, remove the scoring file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score file already exist, removing score file\n"
     ]
    }
   ],
   "source": [
    "# remove previous bikescore.py\n",
    "export_path_base = \"bikescore.py\"\n",
    "import os\n",
    "if os.path.exists(export_path_base):\n",
    "    print(\"score file already exist, removing score file\")\n",
    "    os.remove(export_path_base)\n",
    "else:\n",
    "    print(\"no score file found - safe to continue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write init() and run() functions to score.py file using magic commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting bikescore.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile bikescore.py\n",
    "\n",
    "import numpy as np\n",
    "from numpy import newaxis\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, LSTM, TimeDistributed\n",
    "import pandas as pd\n",
    "import h5py\n",
    "\n",
    "def init():\n",
    "    global trainedmod\n",
    "    from keras.models import load_model\n",
    "    \n",
    "    trainedmod = load_model(\"finalmodel.sav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to bikescore.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a bikescore.py\n",
    "\n",
    "def run(npa):\n",
    "    global trainedmod\n",
    "    \n",
    "    if (len(npa.shape) > 1):\n",
    "        ypred = trainedmod.predict(npa.reshape(npa.shape[0],24,1))\n",
    "    else:\n",
    "        ypred = trainedmod.predict(npa.reshape(1,24,1))\n",
    "    retdf = pd.DataFrame(data={\"Scored Values\":np.squeeze(np.reshape(ypred, newshape= [-1,1]), axis=1)})\n",
    "    return str(retdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to bikescore.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a bikescore.py\n",
    "\n",
    "if __name__ ==\"__main__\":\n",
    "    init()\n",
    "    tmpX = np.array([[   4.50000000e+02,   3.53000000e+02,   2.85000000e+02,   3.32000000e+02,\n",
    "                3.77000000e+02,   2.68000000e+02,   2.18000000e+02,   3.87000000e+02,\n",
    "                8.34000000e+02,   5.08000000e+02,   1.53000000e+02,   4.20000000e+01,\n",
    "                4.00000000e+00,   1.00000000e+00,   1.00000000e+01,   1.70000000e+01,\n",
    "                0.00000000e+00,   4.00000000e+00,   1.00000000e+00,   2.00000000e+00,\n",
    "                5.80000000e-01,   5.45500000e-01,   6.40000000e-01,   3.28400000e-01],\n",
    "            [   8.90000000e+02,   4.50000000e+02,   3.53000000e+02,   2.85000000e+02,\n",
    "                3.32000000e+02,   3.77000000e+02,   2.68000000e+02,   2.18000000e+02,\n",
    "                3.87000000e+02,   8.34000000e+02,   5.08000000e+02,   1.53000000e+02,\n",
    "                4.00000000e+00,   1.00000000e+00,   1.00000000e+01,   1.80000000e+01,\n",
    "                0.00000000e+00,   4.00000000e+00,   1.00000000e+00,   2.00000000e+00,\n",
    "                5.60000000e-01,   5.30300000e-01,   6.40000000e-01,   3.28400000e-01]])\n",
    "    \n",
    "    predY = run(tmpX[0:2,:])\n",
    "    print(predY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def testsavedmodel():\n",
    "    \n",
    "    print(\"R^2 = \", compute_perf(bikescore.trainedmod, tsX, tsY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 =  0.88287373615\n"
     ]
    }
   ],
   "source": [
    "import bikescore\n",
    "bikescore.init()\n",
    "testsavedmodel()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have verified that we have loaded correct model as R^2 value of model saved above is same as the model loaded from the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  4.50000000e+02   3.53000000e+02   2.85000000e+02   3.32000000e+02\n",
      "    3.77000000e+02   2.68000000e+02   2.18000000e+02   3.87000000e+02\n",
      "    8.34000000e+02   5.08000000e+02   1.53000000e+02   4.20000000e+01\n",
      "    4.00000000e+00   1.00000000e+00   1.00000000e+01   1.70000000e+01\n",
      "    0.00000000e+00   4.00000000e+00   1.00000000e+00   2.00000000e+00\n",
      "    5.80000000e-01   5.45500000e-01   6.40000000e-01   3.28400000e-01]\n",
      " [  8.90000000e+02   4.50000000e+02   3.53000000e+02   2.85000000e+02\n",
      "    3.32000000e+02   3.77000000e+02   2.68000000e+02   2.18000000e+02\n",
      "    3.87000000e+02   8.34000000e+02   5.08000000e+02   1.53000000e+02\n",
      "    4.00000000e+00   1.00000000e+00   1.00000000e+01   1.80000000e+01\n",
      "    0.00000000e+00   4.00000000e+00   1.00000000e+00   2.00000000e+00\n",
      "    5.60000000e-01   5.30300000e-01   6.40000000e-01   3.28400000e-01]]\n"
     ]
    }
   ],
   "source": [
    "print(tsX[0:2,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predY = bikescore.run(tsX[0:5,:])\n",
    "trueY=str(pd.DataFrame(data={\"Actual Values\":np.squeeze(np.reshape(tsY[0:5], newshape= [-1,1]), axis=1)}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scored Values \t\t\t Actual Values\n",
      "0     742.635132 \t\t\t 0          890.0\n",
      "1     780.415833 \t\t\t 1          788.0\n",
      "2     570.603760 \t\t\t 2          513.0\n",
      "3     389.780273 \t\t\t 3          387.0\n",
      "4     276.378601 \t\t\t 4          283.0\n"
     ]
    }
   ],
   "source": [
    "for x,y in zip(predY.split('\\n'),trueY.split('\\n')):\n",
    "    print(x.strip(), \"\\t\\t\\t\",y.strip()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate schema file ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from azureml.api.schema.dataTypes import DataTypes\n",
    "from azureml.api.schema.sampleDefinition import SampleDefinition\n",
    "import azureml.api.realtime.services as amlo16n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'main.py'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = {\"npa\": SampleDefinition(DataTypes.NUMPY, tsX[0:3,:])}\n",
    "amlo16n.generate_schema(inputs=inputs,\n",
    "                            filepath=\"bikeschema.json\",\n",
    "                            run_func=bikescore.run)\n",
    "amlo16n.generate_main(user_file=\"bikescore.py\", schema_file=\"bikeschema.json\",\n",
    "                          main_file_name=\"main.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# check score.py and main.py\n",
    "%pycat bikescore.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%pycat main.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Environment ##\n",
    "For cluster deployment, you need to setup you environment with ACS, storage, ACR, AppInsights etc. Cluster deployment expects that you have precreated experimentation and model management account through Ibiza as per instructions in the [Instruction Guide](https://github.com/Azure/ViennaDocs/blob/master/Documentation/Installation.md)\n",
    "\n",
    "You can validate your account using the command shown below\n",
    "\n",
    "```\n",
    "C:\\Users\\neerajkh\\Documents\\BikeForecastNotebook>az ml account modelmanagement list\n",
    "{\n",
    "  \"created_on\": \"2017-08-22T02:34:00.837873Z\",\n",
    "  \"description\": \"\",\n",
    "  \"id\": \"/subscriptions/6d976e3d-6278-4645-ab79-cc5f5fe01a49/resourceGroups/amlgrp2/providers/Microsoft.MachineLearningModelManagement/accounts/neerajteam2hosting\",\n",
    "  \"location\": \"eastus2\",\n",
    "  \"model_management_swagger_location\": \"https://eastus2.modelmanagement.azureml.net/api/subscriptions/6d976e3d-6278-4645-ab79-cc5f5fe01a49/resourceGroups/amlgrp2/accounts/neerajteam2hosting/swagger.json?api-version=2017-09-01-preview\",\n",
    "  \"modified_on\": \"2017-08-22T02:34:00.837873Z\",\n",
    "  \"name\": \"neerajteam2hosting\",\n",
    "  \"resource_group\": \"amlgrp2\",\n",
    "  \"sku\": {\n",
    "    \"capacity\": 1,\n",
    "    \"name\": \"S1\"\n",
    "  },\n",
    "  \"subscription\": \"6d976e3d-6278-4645-ab79-cc5f5fe01a49\",\n",
    "  \"tags\": null,\n",
    "  \"type\": \"Microsoft.MachineLearningModelManagement/accounts\"\n",
    "}\n",
    "```\n",
    "\n",
    "Let's set this account to be the default account for registering models and web services.\n",
    "\n",
    "```\n",
    "C:\\Users\\neerajkh\\Documents\\BikeForecastNotebook>az ml account modelmanagement set -n neerajteam2hosting -g amlgrp2\n",
    "{\n",
    "  \"created_on\": \"2017-08-22T02:34:00.837873Z\",\n",
    "  \"description\": \"\",\n",
    "  \"id\": \"/subscriptions/6d976e3d-6278-4645-ab79-cc5f5fe01a49/resourceGroups/amlgrp2/providers/Microsoft.MachineLearningModelManagement/accounts/neerajteam2hosting\",\n",
    "  \"location\": \"eastus2\",\n",
    "  \"model_management_swagger_location\": \"https://eastus2.modelmanagement.azureml.net/api/subscriptions/6d976e3d-6278-4645-ab79-cc5f5fe01a49/resourceGroups/amlgrp2/accounts/neerajteam2hosting/swagger.json?api-version=2017-09-01-preview\",\n",
    "  \"modified_on\": \"2017-08-22T02:34:00.837873Z\",\n",
    "  \"name\": \"neerajteam2hosting\",\n",
    "  \"resource_group\": \"amlgrp2\",\n",
    "  \"sku\": {\n",
    "    \"capacity\": 1,\n",
    "    \"name\": \"S1\"\n",
    "  },\n",
    "  \"subscription\": \"6d976e3d-6278-4645-ab79-cc5f5fe01a49\",\n",
    "  \"tags\": null,\n",
    "  \"type\": \"Microsoft.MachineLearningModelManagement/accounts\"\n",
    "}\n",
    "```\n",
    "\n",
    "Once model management account is created, the next step is to create an environment. Users can create K8 based ACS cluster environment using the following commands.\n",
    "\n",
    "Let's validate if our environment has been created and if so, then let's set it to be the default environment for our implementation.\n",
    "```\n",
    "C:\\Users\\neerajkh\\Documents\\BikeForecastNotebook>az ml env setup -n amlcluster -c -l eastus2 -g amlgrp2\n",
    "Subscription set to Channels\n",
    "Continue with this subscription (Y/n)? Y\n",
    "Resource group amlgrp2 already exists, skipping creation.\n",
    "waiting for AAD role to propagate.done\n",
    "Provisioning compute resources...\n",
    "Resource creation submitted successfully.\n",
    "Resources may take 10-20 minutes to be completely provisioned.\n",
    "To see if your environment is ready to use, run:\n",
    "  az ml env show -g amlgrp2 -n amlcluster\n",
    "Once your environment has successfully provisioned, you can set it as your target context using:\n",
    "  az ml env set -g amlgrp2 -n amlcluster\n",
    "C:\\Users\\neerajkh\\Documents\\BikeForecastNotebook>az ml env list\n",
    "[\n",
    "  {\n",
    "    \"Cluster Name\": \"amlcluster\",\n",
    "    \"Cluster Size\": 2,\n",
    "    \"Created On\": \"2017-08-22T04:03:09.147000+00:00\",\n",
    "    \"Location\": \"eastus2\",\n",
    "    \"Provisioning State\": \"Succeeded\",\n",
    "    \"Resource Group\": \"amlgrp2\",\n",
    "    \"Subscription\": \"6d976e3d-6278-4645-ab79-cc5f5fe01a49\"\n",
    "  }\n",
    "]\n",
    "C:\\Users\\neerajkh\\Documents\\BikeForecastNotebook>az ml env set -n amlcluster -g amlgrp2\n",
    "Compute set to amlcluster.\n",
    "```\n",
    "\n",
    "You are all set with environment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create web service ###\n",
    "Now you can create web service by using command az ml service and passing scoring file, schema file, dependencies file, and model file as shown below\n",
    "\n",
    "\n",
    "```\n",
    "C:\\Users\\neerajkh\\Documents\\bikeshare1>az ml service create realtime -f bikescore.py -m finalmodel.sav -r python -c .\\aml_config\\conda_dependencies.yml -s bikeschema.json -l true -n bikews1\n",
    "\n",
    "Found existing local service with the same name running at http://127.0.0.1:32781/score\n",
    "Delete existing service and create new service (y/N)? y\n",
    "Service deleted.\n",
    " C:\\Users\\neerajkh\\AppData\\Local\\Temp\\requirementspy1q34aj.txt\n",
    " .\\aml_config\\conda_dependencies.yml\n",
    " finalmodel.sav\n",
    "Successfully registered model\n",
    "Id: 0acb4b7e57ce40f08bf5057a46ab3897\n",
    "More information: 'az ml model show -m 0acb4b7e57ce40f08bf5057a46ab3897'\n",
    "Creating new driver at C:\\Users\\neerajkh\\AppData\\Local\\Temp\\tmpft68nqyb.py\n",
    " bikescore.py\n",
    " bikeschema.json\n",
    "Successfully created manifest\n",
    "Id: 19e49ed5-5952-4338-9334-64000b1ccd27\n",
    "More information: 'az ml manifest show -i 19e49ed5-5952-4338-9334-64000b1ccd27'\n",
    "Creating image...................Done.\n",
    "Image ID: 4497ac1c-3542-4a1f-9dab-3b8e39e77a7f\n",
    "More details: 'az ml image show -i 4497ac1c-3542-4a1f-9dab-3b8e39e77a7f'\n",
    "Usage information: 'az ml image usage -i 4497ac1c-3542-4a1f-9dab-3b8e39e77a7f'\n",
    "[Local mode] Running docker container.\n",
    "[Local mode] Pulling the image from mlcrpacr10f446252934.azurecr.io/bikews1:7. This may take a few minutes, depending on your connection speed...\n",
    "[Local mode] Pulling.................................\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List web service details ###\n",
    "\n",
    "You can list web service details along with calling pattern by using the following command\n",
    "\n",
    "```\n",
    "C:\\Users\\neerajkh\\Documents\\bikeshare1>az ml service list realtime -o table\n",
    "Name      Id        UpdatedAt            State\n",
    "--------  --------  -------------------  -------\n",
    "bikews1   bikews1   2017-09-11T01:52:18  running\n",
    "mnistws1  mnistws1  2017-09-10T18:49:51  running\n",
    "```\n",
    "\n",
    "```\n",
    "C:\\Users\\neerajkh\\Documents\\bikeshare1>az ml service usage realtime -i bikews1\n",
    "Scoring URL:\n",
    "    http://127.0.0.1:32783/score\n",
    "\n",
    "Headers:\n",
    "    Content-Type: application/json\n",
    "\n",
    "Swagger URL:\n",
    "    http://127.0.0.1:32783/swagger.json\n",
    "\n",
    "Sample CLI command:\n",
    "    az ml service run realtime -i bikews1 -d \"!! YOUR DATA HERE !!\"\n",
    "\n",
    "Sample CURL call:\n",
    "    curl -X POST -H \"Content-Type:application/json\" --data \"!! YOUR DATA HERE !!\" http://127.0.0.1:32783/score\n",
    "\n",
    "C:\\Users\\neerajkh\\Documents\\bikeshare1>curl http://127.0.0.1:32783/swagger.json\n",
    "\n",
    "{\"consumes\": [\"application/json\"], \"paths\": {\"/score\": {\"post\": {\"description\": \"Run web service's model and get the prediction output\", \"operationId\": \"RunMLService\", \"parameters\": [{\"schema\": {\"$ref\": \"#/definitions/ServiceInput\"}, \"description\": \"The input payload for executing the real-time machine learning service.\", \"in\": \"body\", \"name\": \"serviceInputPayload\"}], \"responses\": {\"200\": {\"schema\": {\"$ref\": \"#/definitions/ServiceOutput\"}, \"description\": \"The service processed the input correctly and provided a result prediction, if applicable.\"}, \"default\": {\"schema\": {\"$ref\": \"#/definitions/ErrorResponse\"}, \"description\": \"The service failed to execute due to an error.\"}}}}, \"/\": {\"get\": {\"description\": \"Simple health check endpoint to ensure the service is up at any given point.\", \"operationId\": \"ServiceHealthCheck\", \"responses\": {\"200\": {\"schema\": {\"type\": \"string\"}, \"description\": \"If service is up and running, this response will be returned with the content 'Healthy'\", \"examples\": {\"application/json\": \"Healthy\"}}, \"default\": {\"schema\": {\"$ref\": \"#/definitions/ErrorResponse\"}, \"description\": \"The service failed to execute due to an error.\"}}}}}, \"definitions\": {\"ServiceInput\": {\"type\": \"object\", \"example\": {\"npa\": [[450.0, 353.0, 285.0, 332.0, 377.0, 268.0, 218.0, 387.0, 834.0, 508.0, 153.0, 42.0, 4.0, 1.0, 10.0, 17.0, 0.0, 4.0, 1.0, 2.0, 0.58, 0.5455, 0.64, 0.3284], [890.0, 450.0, 353.0, 285.0, 332.0, 377.0, 268.0, 218.0, 387.0, 834.0, 508.0, 153.0, 4.0, 1.0, 10.0, 18.0, 0.0, 4.0, 1.0, 2.0, 0.56, 0.5303, 0.64, 0.3284], [788.0, 890.0, 450.0, 353.0, 285.0, 332.0, 377.0, 268.0, 218.0, 387.0, 834.0, 508.0, 4.0, 1.0, 10.0, 19.0, 0.0, 4.0, 1.0, 2.0, 0.56, 0.5303, 0.68, 0.2985]]}, \"properties\": {\"npa\": {\"type\": \"array\", \"items\": {\"type\": \"array\", \"items\": {\"type\": \"number\", \"format\": \"double\"}}}}}, \"ErrorResponse\": {\"type\": \"object\", \"properties\": {\"status_code\": {\"type\": \"integer\", \"format\": \"int32\"}, \"message\": {\"type\": \"string\"}}}, \"ServiceOutput\": {\"type\": \"object\"}}, \"schemes\": [\"https\"], \"info\": {\"description\": \"API specification for the Azure Machine Learning service ML service\", \"title\": \"ML service\", \"version\": \"1.0\"}, \"produces\": [\"application/json\"], \"swagger\": \"2.0\"}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calling web service ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can call the web service through az ml or curl. Here is the output by calling web service from az ml CLI\n",
    "\n",
    "```\n",
    "C:\\Users\\neerajkh\\Documents\\bikeshare1>az ml service run realtime -i bikews1 -d \"{\\\"npa\\\": [[450.0, 353.0, 285.0, 332.0, 377.0, 268.0, 218.0, 387.0, 834.0, 508.0, 153.0, 42.0, 4.0, 1.0, 10.0, 17.0, 0.0, 4.0, 1.0, 2.0, 0.58, 0.5455, 0.64, 0.3284], [890.0, 450.0, 353.0, 285.0, 332.0, 377.0, 268.0, 218.0, 387.0, 834.0, 508.0, 153.0, 4.0, 1.0, 10.0, 18.0, 0.0, 4.0, 1.0, 2.0, 0.56, 0.5303, 0.64, 0.3284], [788.0, 890.0, 450.0, 353.0, 285.0, 332.0, 377.0, 268.0, 218.0, 387.0, 834.0, 508.0, 4.0, 1.0, 10.0, 19.0, 0.0, 4.0, 1.0, 2.0, 0.56, 0.5303, 0.68, 0.2985]]}\"\n",
    "   Scored Values\n",
    "0     742.635132\n",
    "1     780.415833\n",
    "2     570.603760\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
